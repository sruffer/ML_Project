df.blanks <- data.frame(cols,blanks)
length(df.blanks$cols[df.blanks$blanks>0]) # count is 33 columns
subtrain <- subtrain[,-df.blanks$cols[df.blanks$blanks>0]]
# Remove near zero variance (new_window), and user name and time columns
library(caret)
library(AppliedPredictiveModeling)
nsv<-nearZeroVar(subtrain,saveMetrics=TRUE)
subtrain <- subtrain[,-c(2:6)]
# Check correlation
intercor <- abs(cor(subtrain[,-55]))
diag(intercor) <- 0
which(intercor > 0.8,arr.ind=TRUE)
# Work with random subset of data
set.seed(2015)
sampletrain <- subtrain[sample(nrow(subtrain),500,replace=FALSE),]
# Try models
#modglmpca <- train(classe~.,data=sampletrain,method="glm",preProcess="pca")
#Error in train.default(x, y, weights = w, ...) :
#final tuning parameters could not be determined
#In addition: There were 27 warnings (use warnings() to see them)
modrpart <- train(classe~.,data=sampletrain,method="rpart")
modrpart
modrf <- train(classe~.,data=sampletrain,method="rf",prox=TRUE)
modrf
library(ElemStatLearn)
library(caret)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
subtrainSA <- trainSA[,c(-1,-4,-5)]
subtrainSA$chd <- as.factor(subtrainSA$chd)
subtestSA <- testSA[,c(-1,-4,-5)]
subtestSA$chd <- as.factor(subtestSA$chd)
modfit <- train(subtrainSA$chd ~ .,data=subtrainSA,method="glm",family="binomial")
confusionMatrix(subtestSA$chd,predict(modfit,subtestSA))
?createFolds
library(caret)
?createFolds
traindata <- read.csv("pml-training.csv")
testdata <- read.csv("pml-testing.csv")
# Data Prep
# Remove columns with NAs
cols <- vector()
nas <- vector()
for(i in 1:160) {
count <- 0
count <- length(which(is.na(traindata[,i])))
cols <- c(cols,i)
nas <- c(nas,count)
}
df.na <- data.frame(cols,nas)
length(df.na$cols[df.na$nas>0]) # count is 67 columns
subtrain <- traindata[,-df.na$cols[df.na$nas>0]]
# Remove columns with blanks
cols <- vector()
blanks <- vector()
for(i in 1:93) {
count <- 0
count <- length(which(subtrain[,i]==""))
cols <- c(cols,i)
blanks <- c(blanks,count)
}
df.blanks <- data.frame(cols,blanks)
length(df.blanks$cols[df.blanks$blanks>0]) # count is 33 columns
subtrain <- subtrain[,-df.blanks$cols[df.blanks$blanks>0]]
# Remove near zero variance (new_window), and user name and time columns
library(caret)
library(AppliedPredictiveModeling)
nsv<-nearZeroVar(subtrain,saveMetrics=TRUE)
subtrain <- subtrain[,-c(2:6)]
# Check correlation
intercor <- abs(cor(subtrain[,-55]))
diag(intercor) <- 0
which(intercor > 0.8,arr.ind=TRUE)
# Create training and validation sets from subtrain
inTrain <- createDataPartition(y=subtrain$classe,
p=0.75, list=FALSE)
training <- subtrain[inTrain,]
validation <- spam[-inTrain,]
dim(training)
validation <- subtrain[-inTrain,]
set.seed(2015)
folds <- createFolds(y=training$classe,k=10,
list=TRUE,returnTrain=TRUE)
folds
str(folds)
set.seed(2015)
sampletrain <- subtrain[sample(nrow(subtrain),1000,replace=FALSE),]
# 10-fold CV repeated ten times
fitControl <- trainControl(method = "repeatedcv",number = 10,repeats = 10)
modgbm <- train(classe~., data = sampletrain, method = "gbm",trControl = fitControl,verbose = FALSE)
modgbm
modrpart <- train(classe~.,data=sampletrain,method="rpart",trControl = fitControl)
modrpart
modrf <- train(classe~.,data=sampletrain,method="rf",prox=TRUE,trControl = fitControl)
modrf
plot(sampletrain$classe)
plot(subtrain$classe)
inTrain <- createDataPartition(y=subtrain$classe,
p=0.95, list=FALSE)
training <- subtrain[inTrain,]
validation <- subtrain[-inTrain,]
predict_gbm <- predict(modgbm,validation)
missClass(validation$classe,as.numeric(predict_gbm)-1)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(validation$classe,as.numeric(predict_gbm)-1)
predict_gbm[1:10]
validation$classe[1:10]
confusionMatrix(validation$classe,predict(modgbm,validation))
confusionMatrix(validation$classe,predict(modrpart,validation))
confusionMatrix(validation$classe,predict(modrf,validation))
set.seed(2015)
sampletrain <- training[sample(nrow(training),1000,replace=FALSE),]
fitControl <- trainControl(method = "repeatedcv",number = 5,repeats = 5)
modrf <- train(classe~.,data=sampletrain,method="rf",prox=TRUE,trControl = fitControl)
modrf
modrpart <- train(classe~.,data=sampletrain,method="rpart",trControl = fitControl)
modrpart
plot(sampletrain$classe)
modgbm <- train(classe~., data = sampletrain, method = "gbm",trControl = fitControl,verbose = FALSE)
modgbm
confusionMatrix(validation$classe,predict(modgbm,validation))
confusionMatrix(validation$classe,predict(modrpart,validation))
confusionMatrix(validation$classe,predict(modrf,validation))
fitControl <- trainControl(method = "repeatedcv",number = 3,repeats = 3)
modgbm <- train(classe~., data = sampletrain, method = "gbm",trControl = fitControl,verbose = FALSE)
modgbm
confusionMatrix(validation$classe,predict(modgbm,validation))
?gbm
library(gbm)
?rf
traindata <- read.csv("pml-training.csv")
testdata <- read.csv("pml-testing.csv")
# Data Prep
# Remove columns with NAs
cols <- vector()
nas <- vector()
for(i in 1:160) {
count <- 0
count <- length(which(is.na(traindata[,i])))
cols <- c(cols,i)
nas <- c(nas,count)
}
df.na <- data.frame(cols,nas)
length(df.na$cols[df.na$nas>0]) # count is 67 columns
subtrain <- traindata[,-df.na$cols[df.na$nas>0]]
# Remove columns with blanks
cols <- vector()
blanks <- vector()
for(i in 1:93) {
count <- 0
count <- length(which(subtrain[,i]==""))
cols <- c(cols,i)
blanks <- c(blanks,count)
}
df.blanks <- data.frame(cols,blanks)
length(df.blanks$cols[df.blanks$blanks>0]) # count is 33 columns
subtrain <- subtrain[,-df.blanks$cols[df.blanks$blanks>0]]
# Remove near zero variance (new_window), and user name and time columns
library(caret)
library(AppliedPredictiveModeling)
nsv<-nearZeroVar(subtrain,saveMetrics=TRUE)
subtrain <- subtrain[,-c(2:6)]
inTrain <- createDataPartition(y=subtrain$classe,
p=0.75, list=FALSE)
training <- subtrain[inTrain,]
validation <- subtrain[-inTrain,]
set.seed(2015)
sampletrain <- training[sample(nrow(training),1000,replace=FALSE),]
fitControl <- trainControl(method = "repeatedcv",number = 10,repeats = 5)
library(gbm)
modgbm <- train(classe~., data = sampletrain, method = "gbm",trControl = fitControl,verbose = FALSE)
modgbm
modrf <- train(classe~.,data=sampletrain,method="rf",prox=TRUE,trControl = fitControl)
modrf
confusionMatrix(validation$classe,predict(modgbm,validation))
confusionMatrix(validation$classe,predict(modrf,validation))
.Random.seed
set.seed(2015)
set.seed(2015)
model_gbm <- train(classe~., data = training, method = "gbm",trControl = fitControl,verbose = FALSE)
model_gbm
confusionMatrix(validation$classe,predict(modgbm,validation))
traindata <- read.csv("pml-training.csv")
testdata <- read.csv("pml-testing.csv")
# Data Prep
# Remove columns with NAs
cols <- vector()
nas <- vector()
for(i in 1:160) {
count <- 0
count <- length(which(is.na(traindata[,i])))
cols <- c(cols,i)
nas <- c(nas,count)
}
df.na <- data.frame(cols,nas)
length(df.na$cols[df.na$nas>0]) # count is 67 columns
subtrain <- traindata[,-df.na$cols[df.na$nas>0]]
# Remove columns with blanks
cols <- vector()
blanks <- vector()
for(i in 1:93) {
count <- 0
count <- length(which(subtrain[,i]==""))
cols <- c(cols,i)
blanks <- c(blanks,count)
}
df.blanks <- data.frame(cols,blanks)
length(df.blanks$cols[df.blanks$blanks>0]) # count is 33 columns
subtrain <- subtrain[,-df.blanks$cols[df.blanks$blanks>0]]
# Remove near zero variance (new_window), and user name and time columns
library(caret)
library(AppliedPredictiveModeling)
nsv<-nearZeroVar(subtrain,saveMetrics=TRUE)
subtrain <- subtrain[,-c(2:6)]
# Create training and validation sets from subtrain
set.seed(2015)
inTrain <- createDataPartition(y=subtrain$classe,
p=0.75, list=FALSE)
training <- subtrain[inTrain,]
validation <- subtrain[-inTrain,]
fitControl <- trainControl(method = "repeatedcv",number = 10,repeats = 5)
library(randomForest)
model_rf <- train(classe~.,data=training,method="rf",prox=TRUE,trControl = fitControl)
traindata <- read.csv("pml-training.csv")
testdata <- read.csv("pml-testing.csv")
# Data Prep
# Remove columns with NAs
cols <- vector()
nas <- vector()
for(i in 1:160) {
count <- 0
count <- length(which(is.na(traindata[,i])))
cols <- c(cols,i)
nas <- c(nas,count)
}
df.na <- data.frame(cols,nas)
length(df.na$cols[df.na$nas>0]) # count is 67 columns
subtrain <- traindata[,-df.na$cols[df.na$nas>0]]
# Remove columns with blanks
cols <- vector()
blanks <- vector()
for(i in 1:93) {
count <- 0
count <- length(which(subtrain[,i]==""))
cols <- c(cols,i)
blanks <- c(blanks,count)
}
df.blanks <- data.frame(cols,blanks)
length(df.blanks$cols[df.blanks$blanks>0]) # count is 33 columns
subtrain <- subtrain[,-df.blanks$cols[df.blanks$blanks>0]]
# Remove near zero variance (new_window), and user name and time columns
library(caret)
library(AppliedPredictiveModeling)
nsv<-nearZeroVar(subtrain,saveMetrics=TRUE)
subtrain <- subtrain[,-c(2:6)]
# Create training and validation sets from subtrain
set.seed(2015)
inTrain <- createDataPartition(y=subtrain$classe,
p=0.75, list=FALSE)
training <- subtrain[inTrain,]
validation <- subtrain[-inTrain,]
model_gbm <- train(classe~., data = training, method = "gbm",verbose = FALSE)
model_gbm
confusionMatrix(validation$classe,predict(model_gbm,validation))
Sys.time()
Sys.time()
fitControl <- trainControl(method = "cv",number = 3)
model_gbm_cv <- train(classe~., data = training, method = "gbm",verbose = FALSE,trControl = fitControl)
Sys.time()
model_gbm_cv
confusionMatrix(validation$classe,predict(model_gbm_cv,validation))
confusionMatrix(validation$classe,predict(model_gbm_cv,testdata))
source('~/Coursera/WorkingDir/MLProjectFinalPrep.R', echo=TRUE)
str(subtest$classe)
str(testdata)
str(subtest)
subtest$classe
View(subtest)
which(names(subtest) != names(subtrain))
names(subtrain[,55])
names(subtrain[55])
names(subtest[55])
View(subtrain)
confusionMatrix(answers,predict(model_gbm_cv,subtest))
answers <- rep("",20)
confusionMatrix(answers,predict(model_gbm_cv,subtest))
?vector
answers <- vector(mode="character",length=20)
confusionMatrix(answers,predict(model_gbm_cv,subtest))
?predict
answers <- vector(mode="character",length=20)
answers <- predict(model_gbm_cv,subtest)
answers
str(answers)
summary(answers)
View(subtest)
?varImp
varImp(model_gbm_cv)
plot(subtrain$classe,subtrain$num_window)
line(mean(subtrain$num_window))
traindata <- read.csv("pml-training.csv")
testdata <- read.csv("pml-testing.csv")
# Data Prep
# Remove columns with NAs
cols <- vector()
nas <- vector()
for(i in 1:160) {
count <- 0
count <- length(which(is.na(traindata[,i])))
cols <- c(cols,i)
nas <- c(nas,count)
}
df.na <- data.frame(cols,nas)
length(df.na$cols[df.na$nas>0]) # count is 67 columns
subtrain <- traindata[,-df.na$cols[df.na$nas>0]]
# Remove columns with blanks
cols <- vector()
blanks <- vector()
for(i in 1:93) {
count <- 0
count <- length(which(subtrain[,i]==""))
cols <- c(cols,i)
blanks <- c(blanks,count)
}
df.blanks <- data.frame(cols,blanks)
length(df.blanks$cols[df.blanks$blanks>0]) # count is 33 columns
subtrain <- subtrain[,-df.blanks$cols[df.blanks$blanks>0]]
View(subtrain)
suppressMessages(library(caret))
suppressMessages(library(AppliedPredictiveModeling))
nsv<-nearZeroVar(subtrain,saveMetrics=TRUE)
nsv
subtrain <- subtrain[,-c(1:6)]
subtest <- testdata[,-df.na$cols[df.na$nas>0]]
subtest <- subtest[,-df.blanks$cols[df.blanks$blanks>0]]
subtest <- subtest[,-c(1:6)]
# Create training and validation sets from subtrain
set.seed(2015)
inTrain <- createDataPartition(y=subtrain$classe,
p=0.75, list=FALSE)
training <- subtrain[inTrain,]
validation <- subtrain[-inTrain,]
suppressMessages(library(gbm))
fitControl <- trainControl(method = "cv",number = 3)
model_gbm_cv <- train(classe~., data = training, method = "gbm",verbose = FALSE,trControl = fitControl)
model_gbm_cv
confusionMatrix(validation$classe,predict(model_gbm_cv,validation))
fitControl <- trainControl(method = "cv",number = 10)
Sys.time()
model_gbm_cv <- train(classe~., data = training, method = "gbm",verbose = FALSE,trControl = fitControl)
Sys.time()
model_gbm_cv
confusionMatrix(validation$classe,predict(model_gbm_cv,validation))
varImp
varImp(model_gbm_cv)
?varImp
plot(subtrain$num_window)
answers <- vector(mode="character",length=20)
answers <- predict(model_gbm_cv,subtest)
answers
View(testdata)
traindata <- read.csv("pml-training.csv")
testdata <- read.csv("pml-testing.csv")
# Data Prep
# Remove columns with NAs
cols <- vector()
nas <- vector()
for(i in 1:160) {
count <- 0
count <- length(which(is.na(traindata[,i])))
cols <- c(cols,i)
nas <- c(nas,count)
}
df.na <- data.frame(cols,nas)
length(df.na$cols[df.na$nas>0]) # count is 67 columns
subtrain <- traindata[,-df.na$cols[df.na$nas>0]]
# Remove columns with blanks
cols <- vector()
blanks <- vector()
for(i in 1:93) {
count <- 0
count <- length(which(subtrain[,i]==""))
cols <- c(cols,i)
blanks <- c(blanks,count)
}
df.blanks <- data.frame(cols,blanks)
length(df.blanks$cols[df.blanks$blanks>0]) # count is 33 columns
subtrain <- subtrain[,-df.blanks$cols[df.blanks$blanks>0]]
# Remove near zero variance (new_window), X and user name and time columns
suppressMessages(library(caret))
suppressMessages(library(AppliedPredictiveModeling))
nsv<-nearZeroVar(subtrain,saveMetrics=TRUE)
subtrain <- subtrain[,-c(1:7)]
# Repeat for testdata
subtest <- testdata[,-df.na$cols[df.na$nas>0]]
subtest <- subtest[,-df.blanks$cols[df.blanks$blanks>0]]
subtest <- subtest[,-c(1:7)]
set.seed(2015)
inTrain <- createDataPartition(y=subtrain$classe,
p=0.75, list=FALSE)
training <- subtrain[inTrain,]
validation <- subtrain[-inTrain,]
suppressMessages(library(gbm))
fitControl <- trainControl(method = "cv",number = 10)
Sys.time() # "2015-03-18 15:53:00 PDT"
model_gbm_cv <- train(classe~., data = training, method = "gbm",verbose = FALSE,trControl = fitControl)
Sys.time() # "2015-03-18 16:05:48 PDT"
suppressMessages(library(randomForest))
Sys.time() # ""
model_rf_cv <- train(classe~.,data=sampletrain,method="rf",prox=TRUE,trControl = fitControl)
Sys.time() # ""
Sys.time() # ""
model_rf_cv <- train(classe~.,data=training,method="rf",prox=TRUE,trControl = fitControl)
warnings()
model_gbm_cv
confusionMatrix(validation$classe,predict(model_gbm_cv,validation))
varImp(model_gbm_cv)
answers <- vector(mode="character",length=20)
answers <- predict(model_gbm_cv,subtest)
answers
?randomForest
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(answers)
plot(traindata$classe,traindata$X)
names(training)
plot(traindata$classe,traindata$roll_belt)
plot(traindata$classe,traindata$pitch_belt)
varImp(model_gbm_cv)
suppressMessages(library(caret))
varImp(model_gbm_cv)
plot(traindata$classe,traindata$pitch_forearm)
plot(traindata$classe,traindata$magnet_dumbbell_z)
plot(traindata$classe,traindata$yaw_belt)
plot(traindata$classe,traindata$magnet_dumbbell_y)
plot(traindata$classe,traindata$roll_forearm)
library(AppliedPredictiveModeling)
transparentTheme(trans = .4)
library(caret)
featurePlot(x = training[, 1:3],
y = training$classe,
plot = "pairs",
## Add a key at the top
auto.key = list(columns = 3))
featurePlot(x = training[, 1:3],
y = training$classe,
plot = "ellipse",
## Add a key at the top
auto.key = list(columns = 5))
featurePlot(x = training[, 1:3],
y = training$classe,
plot = "box",
## Pass in options to bwplot()
scales = list(y = list(relation="free"),
x = list(rot = 90)),
layout = c(3,1 ),
auto.key = list(columns = 2))
featurePlot(x = training[, 4:6],
y = training$classe,
plot = "box",
## Pass in options to bwplot()
scales = list(y = list(relation="free"),
x = list(rot = 90)),
layout = c(3,1 ),
auto.key = list(columns = 2))
featurePlot(x = training[, 7:10],
y = training$classe,
plot = "box",
## Pass in options to bwplot()
scales = list(y = list(relation="free"),
x = list(rot = 90)),
layout = c(4,1 ),
auto.key = list(columns = 2))
featurePlot(x = training[, 1:4],
y = training$classe,
plot = "box",
## Pass in options to bwplot()
scales = list(y = list(relation="free"),
x = list(rot = 90)),
layout = c(4,1 ),
auto.key = list(columns = 2))
setwd("~/Coursera/ML_Project")
names(subtrain[1:52])
answers <- predict(model_gbm_cv,testdata)
answers
confusionMatrix(validation$classe,predict(model_gbm_cv,validation))
model_gbm_cv
confusionMatrix(validation$classe,predict(model_gbm_cv,validation))$Accuracy
names(confusionMatrix(validation$classe,predict(model_gbm_cv,validation)))
confusionMatrix(validation$classe,predict(model_gbm_cv,validation))$table
confusionMatrix(validation$classe,predict(model_gbm_cv,validation))$overall
confusionMatrix(validation$classe,predict(model_gbm_cv,validation))$overall[1]
names(model_gbm_cv)
plot(traindata$classe,traindata$X)
plot(traindata$classe,traindata$X, xlab="Classe", ylab"X")
plot(traindata$classe,traindata$X, xlab="Classe", ylab="X")
with(traindata(plot(classe,X, xlab="Classe", ylab="X",colour=classe))
)
with(traindata,plot(classe,X, xlab="Classe", ylab="X",colour=classe)))
with(traindata,plot(classe,X, xlab="Classe", ylab="X",colour=classe))
with(traindata,plot(classe,X, xlab="Classe", ylab="X",colour="red"))
with(traindata,plot(classe,X, xlab="Classe", ylab="X",fill="red"))
with(traindata,plot(classe,X, xlab="Classe", ylab="X"))
